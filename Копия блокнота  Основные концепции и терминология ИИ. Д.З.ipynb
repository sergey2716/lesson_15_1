{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1pbt5Y0dMFmtyc-BDB8AOs4prAEbwVOsR","timestamp":1738485709874}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Домашнее задание\n","\n","Ознакомьтесь с приведёнными ниже примерами использования алгоритмов МО и НС для решения задачи распознавания рукописных цифр.\n","\n","## Порядок выполнения ДЗ\n","\n","1. Сделайте копию данного блокнота себе на диск. Далее работайте со своей копией блокнота. Сохраняйте вносимые в неё изменения.\n","2. Ознакомьтесь с теоретическим текстом и кодом из настоящего блокнота.\n","3. Перенесите примеры кода в отдельные кодовые ячейки и выполните их.\n","4. Создайте тестовую ячейку, куда запишите ответы на теоретические вопросы.\n","5. Расшарьте блокнот и используйте ссылку как ответ на ДЗ."],"metadata":{"id":"SeivPBkJjNUr"}},{"cell_type":"markdown","source":["### Учебный пример: Рещение задачи классификация рукописных цифр с использованием машинного обучения, глубокого обучения и нейронных сетей\n","\n","В этом задании мы будем использовать набор данных MNIST, который содержит изображения рукописных цифр (от 0 до 9). Мы реализуем три различных подхода к классификации этих изображений:\n","\n","1. **Машинное обучение**: Используем метод k-ближайших соседей (k-NN).\n","2. **Глубокое обучение**: Используем многослойный перцептрон (MLP).\n","3. **Нейронные сети**: Используем сверточную нейронную сеть (CNN).\n","\n","### Шаг 1: Установка библиотек\n","\n","Установите необходимые библиотеки:\n","\n","```bash\n","pip install numpy pandas scikit-learn tensorflow keras\n","```\n","\n","### Шаг 2: Загрузка и предобработка данных\n","\n","```python\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import fetch_openml\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.utils import to_categorical\n","\n","# Загрузка данных MNIST\n","mnist = fetch_openml('mnist_784', version=1)\n","X, y = mnist.data / 255.0, mnist.target.astype(int)\n","\n","# Разделение данных на обучающую и тестовую выборки\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","```\n","\n","### Шаг 3: Алгоритм машинного обучения (k-NN)\n","\n","```python\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Создание и обучение модели k-NN\n","knn = KNeighborsClassifier(n_neighbors=3)\n","knn.fit(X_train, y_train)\n","\n","# Прогнозирование на тестовой выборке\n","y_pred_knn = knn.predict(X_test)\n","accuracy_knn = accuracy_score(y_test, y_pred_knn)\n","\n","print(f'Accuracy of k-NN: {accuracy_knn:.4f}')\n","```\n","\n","### Шаг 4: Глубокое обучение (MLP)\n","\n","```python\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","\n","# Предобработка меток для MLP\n","y_train_mlp = to_categorical(y_train, 10)\n","y_test_mlp = to_categorical(y_test, 10)\n","\n","# Создание модели MLP\n","model_mlp = Sequential([\n","    Flatten(input_shape=(784,)),\n","    Dense(128, activation='relu'),\n","    Dense(64, activation='relu'),\n","    Dense(10, activation='softmax')\n","])\n","\n","# Компиляция и обучение модели MLP\n","model_mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model_mlp.fit(X_train, y_train_mlp, epochs=10, batch_size=32, validation_split=0.2)\n","\n","# Оценка модели на тестовой выборке\n","loss_mlp, accuracy_mlp = model_mlp.evaluate(X_test, y_test_mlp)\n","\n","print(f'Accuracy of MLP: {accuracy_mlp:.4f}')\n","```\n","\n","### Шаг 5: Нейронные сети (CNN)\n","\n","```python\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n","\n","# Предобработка данных для CNN\n","X_train_cnn = X_train.values.reshape(-1, 28, 28, 1)\n","X_test_cnn = X_test.values.reshape(-1, 28, 28, 1)\n","y_train_cnn = to_categorical(y_train, 10)\n","y_test_cnn = to_categorical(y_test, 10)\n","\n","# Создание модели CNN\n","model_cnn = Sequential([\n","    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Dropout(0.25),\n","    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Dropout(0.25),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(10, activation='softmax')\n","])\n","\n","# Компиляция и обучение модели CNN\n","model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model_cnn.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=32, validation_split=0.2)\n","\n","# Оценка модели на тестовой выборке\n","loss_cnn, accuracy_cnn = model_cnn.evaluate(X_test_cnn, y_test_cnn)\n","\n","print(f'Accuracy of CNN: {accuracy_cnn:.4f}')\n","```\n","\n","### Заключение\n","\n","В этом задании мы реализовали три различных подхода к классификации изображений рукописных цифр с использованием средств машинного обучения (k-NN), глубокого обучения (MLP) и нейронных сетей (CNN). Мы увидели, что каждый из этих подходов имеет свои преимущества и недостатки, и что сложные модели глубокого обучения могут значительно улучшить точность классификации по сравнению с простыми моделями машинного обучения.\n","\n","### Теоритические вопросы\n","\n","1. Какие преимущества и недостатки использованных методов вы увидели?\n","2. В чем, на ваш взгляд, заключается принципиальная разница между многослойным перцептроном и сверточной нейронной сетью?\n","3. Какие методы предобработки данных были использованы в этом задании?\n"],"metadata":{"id":"vGMR-kTge1Wr"}},{"cell_type":"markdown","source":["Установка библиотек\n"],"metadata":{"id":"wv_nXW0GCRLH"}},{"cell_type":"code","source":["!pip install numpy pandas scikit-learn tensorflow keras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"lg1XaUK8Ceri","executionInfo":{"status":"ok","timestamp":1738489411250,"user_tz":-300,"elapsed":3941,"user":{"displayName":"Сергей Аввакумов","userId":"05978259257614258387"}},"outputId":"c7ce2362-f465-4929-8601-5d1131b8b3cf"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n"]}]},{"cell_type":"markdown","source":["Шаг 2: Загрузка и предобработка данных"],"metadata":{"id":"la8x1nKSC9Au"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import fetch_openml\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.utils import to_categorical\n","\n","# Загрузка данных MNIST\n","mnist = fetch_openml('mnist_784', version=1)\n","X, y = mnist.data / 255.0, mnist.target.astype(int)\n","\n","# Разделение данных на обучающую и тестовую выборки\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"V5qU_OMOC_Uw","executionInfo":{"status":"ok","timestamp":1738489509951,"user_tz":-300,"elapsed":10673,"user":{"displayName":"Сергей Аввакумов","userId":"05978259257614258387"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Шаг 3: Алгоритм машинного обучения (k-NN)"],"metadata":{"id":"hd53PMI1Db2D"}},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Создание и обучение модели k-NN\n","knn = KNeighborsClassifier(n_neighbors=3)\n","knn.fit(X_train, y_train)\n","\n","# Прогнозирование на тестовой выборке\n","y_pred_knn = knn.predict(X_test)\n","accuracy_knn = accuracy_score(y_test, y_pred_knn)\n","\n","print(f'Accuracy of k-NN: {accuracy_knn:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fN89E1ahDQCR","executionInfo":{"status":"ok","timestamp":1738489679715,"user_tz":-300,"elapsed":52425,"user":{"displayName":"Сергей Аввакумов","userId":"05978259257614258387"}},"outputId":"3804a8e0-4c33-4562-e4b1-9c0762dab764"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of k-NN: 0.9713\n"]}]},{"cell_type":"markdown","source":["Шаг 4: Глубокое обучение (MLP)"],"metadata":{"id":"gtCHwK6XD9rN"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","\n","# Предобработка меток для MLP\n","y_train_mlp = to_categorical(y_train, 10)\n","y_test_mlp = to_categorical(y_test, 10)\n","\n","# Создание модели MLP\n","model_mlp = Sequential([\n","    Flatten(input_shape=(784,)),\n","    Dense(128, activation='relu'),\n","    Dense(64, activation='relu'),\n","    Dense(10, activation='softmax')\n","])\n","\n","# Компиляция и обучение модели MLP\n","model_mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model_mlp.fit(X_train, y_train_mlp, epochs=10, batch_size=32, validation_split=0.2)\n","\n","# Оценка модели на тестовой выборке\n","loss_mlp, accuracy_mlp = model_mlp.evaluate(X_test, y_test_mlp)\n","\n","print(f'Accuracy of MLP: {accuracy_mlp:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"wcKMQmL1EL00","executionInfo":{"status":"ok","timestamp":1738489978818,"user_tz":-300,"elapsed":183848,"user":{"displayName":"Сергей Аввакумов","userId":"05978259257614258387"}},"outputId":"36c53147-f70b-4b88-9caf-6684758bc022"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.8608 - loss: 0.4745 - val_accuracy: 0.9474 - val_loss: 0.1767\n","Epoch 2/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.9650 - loss: 0.1141 - val_accuracy: 0.9632 - val_loss: 0.1150\n","Epoch 3/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.9781 - loss: 0.0721 - val_accuracy: 0.9693 - val_loss: 0.0973\n","Epoch 4/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.9847 - loss: 0.0520 - val_accuracy: 0.9705 - val_loss: 0.0969\n","Epoch 5/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - accuracy: 0.9877 - loss: 0.0405 - val_accuracy: 0.9706 - val_loss: 0.1009\n","Epoch 6/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.9897 - loss: 0.0317 - val_accuracy: 0.9734 - val_loss: 0.0928\n","Epoch 7/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.0247 - val_accuracy: 0.9677 - val_loss: 0.1178\n","Epoch 8/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - accuracy: 0.9930 - loss: 0.0202 - val_accuracy: 0.9726 - val_loss: 0.1045\n","Epoch 9/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.9932 - loss: 0.0185 - val_accuracy: 0.9712 - val_loss: 0.1216\n","Epoch 10/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0188 - val_accuracy: 0.9757 - val_loss: 0.0997\n","\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9758 - loss: 0.0918\n","Accuracy of MLP: 0.9758\n"]}]},{"cell_type":"markdown","source":["Шаг 5: Нейронные сети (CNN)"],"metadata":{"id":"mE-gGJTZFHPi"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n","\n","# Предобработка данных для CNN\n","X_train_cnn = X_train.values.reshape(-1, 28, 28, 1)\n","X_test_cnn = X_test.values.reshape(-1, 28, 28, 1)\n","y_train_cnn = to_categorical(y_train, 10)\n","y_test_cnn = to_categorical(y_test, 10)\n","\n","# Создание модели CNN\n","model_cnn = Sequential([\n","    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Dropout(0.25),\n","    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Dropout(0.25),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(10, activation='softmax')\n","])\n","\n","# Компиляция и обучение модели CNN\n","model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model_cnn.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=32, validation_split=0.2)\n","\n","# Оценка модели на тестовой выборке\n","loss_cnn, accuracy_cnn = model_cnn.evaluate(X_test_cnn, y_test_cnn)\n","\n","print(f'Accuracy of CNN: {accuracy_cnn:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"B9jH3sDrFQW0","executionInfo":{"status":"ok","timestamp":1738493305036,"user_tz":-300,"elapsed":3217904,"user":{"displayName":"Сергей Аввакумов","userId":"05978259257614258387"}},"outputId":"b0a9a8a1-276b-49f2-e7b4-fc94afe69abf"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 227ms/step - accuracy: 0.8102 - loss: 0.5767 - val_accuracy: 0.9801 - val_loss: 0.0658\n","Epoch 2/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 223ms/step - accuracy: 0.9634 - loss: 0.1230 - val_accuracy: 0.9825 - val_loss: 0.0561\n","Epoch 3/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 224ms/step - accuracy: 0.9732 - loss: 0.0896 - val_accuracy: 0.9865 - val_loss: 0.0426\n","Epoch 4/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 222ms/step - accuracy: 0.9772 - loss: 0.0747 - val_accuracy: 0.9882 - val_loss: 0.0404\n","Epoch 5/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 201ms/step - accuracy: 0.9800 - loss: 0.0640 - val_accuracy: 0.9890 - val_loss: 0.0347\n","Epoch 6/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 226ms/step - accuracy: 0.9819 - loss: 0.0582 - val_accuracy: 0.9897 - val_loss: 0.0337\n","Epoch 7/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 212ms/step - accuracy: 0.9845 - loss: 0.0514 - val_accuracy: 0.9902 - val_loss: 0.0316\n","Epoch 8/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 218ms/step - accuracy: 0.9847 - loss: 0.0487 - val_accuracy: 0.9891 - val_loss: 0.0372\n","Epoch 9/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 212ms/step - accuracy: 0.9849 - loss: 0.0480 - val_accuracy: 0.9899 - val_loss: 0.0345\n","Epoch 10/10\n","\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 215ms/step - accuracy: 0.9869 - loss: 0.0408 - val_accuracy: 0.9912 - val_loss: 0.0311\n","\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9903 - loss: 0.0302\n","Accuracy of CNN: 0.9907\n"]}]},{"cell_type":"markdown","source":["\"\"\"Теоритические вопросы\n","1. Какие преимущества и недостатки использованных методов вы увидели?\n","2. В чем,на ваш взгляд, заключается принципиальная разница между многослойным перцептроном и сверточной нейронной сетью?\n","3. Какие методы предобработки данных были использованы в этом задании?\n","                        ОТВЕТ\n","1. Преимущества и недостатки использованных методов\n","                     Преимущества:\n","Метод k-ближайших соседей (k-NN): Простота и легкость в реализации. Не требует предварительного обучения модели, что\n","позволяет быстро проводить тестирование. Может быть эффективным на небольших наборах данных.\n","Многослойный перцептрон (MLP): Способен моделировать сложные нелинейные зависимости. После обучения предсказания\n","выполняются быстро, так как не требуется анализировать всю обучающую выборку. Гибкость в применении для различных задач\n","классификации и регрессии.\n","Сверточная нейронная сеть (CNN): Эффективно извлекает пространственные признаки из изображений, что значительно улучшает\n","качество классификации. Автоматически определяет важные признаки, что снижает необходимость в ручной предобработке.\n","Способна обрабатывать изображения с различными размерами и ориентацией.\n","\n","                        Недостатки:\n","Метод k-ближайших соседей (k-NN): Высокая вычислительная сложность при предсказании, особенно на больших наборах данных,\n","так как нужно сравнивать новое значение с каждым элементом обучающей выборки. Чувствителен к шуму и выбросам в данных.\n","Неэффективен при высокой размерности данных (проклятие размерности).\n","Многослойный перцептрон (MLP): Требует значительного объема данных для достижения хороших результатов и предотвращения\n","переобучения. Не оптимизирован для обработки изображений, так как не учитывает пространственные связи между пикселями.\n","Сверточная нейронная сеть (CNN): Сложность архитектуры и процесса обучения, требующая больше времени и вычислительных\n","ресурсов. Зависит от подбора гиперпараметров и архитектуры, что может требовать значительных усилий для оптимизации.\n","Может быть подвержена переобучению при недостаточном количестве данных.\n","\n","2. Принципиальная разница между многослойным перцептроном и сверточной нейронной сетью.\n","Основная разница между многослойным перцептроном (MLP) и сверточной нейронной сетью (CNN) заключается в способе\n","обработки данных:\n","MLP:\n","Состоит из полносвязных слоев, где каждый нейрон связан со всеми нейронами предыдущего слоя. Не учитывает\n","пространственные зависимости, что делает его менее эффективным для обработки изображений. Для работы с изображениями\n","требуется предварительное преобразование в векторный формат, что может привести к потере информации о пространственной\n","структуре. CNN:\n","Использует свертки, которые сосредоточены на локальных участках изображения и позволяют модели выявлять\n","пространственные зависимости. Содержит слои подвыборки (пулинга), которые уменьшают размерность данных и позволяют\n","сосредоточиться на наиболее значимых признаках. Имеет меньшую сложность в плане параметров по сравнению с MLP,\n","что позволяет лучше обобщать на новых данных.\n","\n","3. Методы предобработки данных В этом задании были использованы следующие методы предобработки данных:\n","Нормализация:\n","Данные изображения были нормализованы путем деления на 255, чтобы привести значения пикселей в диапазон от 0 до 1.\n","Это улучшает сходимость алгоритмов обучения. Разделение выборки:\n","Данные были разделены на обучающую и тестовую выборки с использованием функции train_test_split, что позволяет оценить\n","производительность модели на невидимых данных.\n","Преобразование меток:\n","Метки классов для MLP были преобразованы в формат one-hot с использованием функции to_categorical, что позволяет\n","модели корректно интерпретировать многоклассовую задачу.\n","Изменение формы данных для CNN:\n","Данные были преобразованы в трехмерный формат (28, 28, 1), что соответствует формату изображений с одним цветовым\n","каналом (градации серого), позволяя CNN обрабатывать данные должным образом. GPT-4o mini\"\"\""],"metadata":{"id":"wU4eZ6KLRtqC"}}]}